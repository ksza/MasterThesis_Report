%************************************************
\chapter{Introduction}\label{ch:introduction}
%************************************************

Before the early 1970s, computers were owned by large institutions like corporations, universities or government agencies. These machines, also know as \emph{Mainframes}, were costly and space consuming, most institutions owning only one piece of such equipment. Lacking any kind of user interface, Mainframes would accept jobs in the form of punched cards, an early input mechanism for data and programs into computers. A group of people in the institutions were instructed how to use the machines (creating punched cards, operating the machines) and they represented the interface between everyday users and the Mainframe. Quite a bottleneck!\\

In 1971 the first commercial microprocessor was released, representing the rise of a new era: the Personal Computer (PC). The PC represented a huge step forward, offering in perspective the possibility for anyone to own a computer and to operate it using novel input/output mechanism: graphical user interface, mouse, keyboard and other peripherals. This is the standard PC setup that we know and, after such o along time, still use. By this I want to point that although we have came a long way, by hardware and software advancements, the human computer interaction (HCI) form that is mostly used to interact with PCs is just as it was envisioned a little more than 40 years ago.\\

The PCs revolution was followed by the idea of portable personal devices like laptops, dynabooks (an educational device similar to a nowadays tablet). Although novel at that time, all the fever generated by this revolution was viewed by a group of people at PARC\footnote{Palo Alto Research Center} as being ephemeral: ''[...] My colleagues and I at PARC think that the idea of a ''personal computer'' itself is misplaced, and that the vision of laptop machines, dynabooks and ''knowledge navigators'' is only a transitional step toward achieving the real potential of information technology. Such machines cannot truly make computing an integral, invisible part of the way people live their lives. Therefore we are trying to conceive a new way of thinking about computers in the world, one that takes into account the natural human environment and allows the computers themselves to vanish into the background''. \cite{weiser1991computer}. This futuristic concept envisioned at PARC which further shaped the way we see and use technology and devices is known as \emph{ubicomp}\footnote{Ubiquitous Computing}.\\

The novel vision in ubicomp can be viewed as a second major advancement in the world of technology. The first major advancement, the transition from Mainframe to PC, took the relation between people and computer from a many-to-one to a one-to-one relationship. Ubicomp envisioned a transition from one-to-one to many-to-one, where each user will own not one but many device. These device would not be only PCs, they would be all sorts of portable device, some specialized at accomplishing specific tasks and performing under various circumstances. Classical HCI was not fit for this new set-up. More advanced and more intuitive concepts were needed to make the best of these technological advances. One such emerging concept was \emph{context-aware computing}. Context is ''any information that can be used to characterize the situation of an entity, where an entity can be a person, place, or physical or computational object. We define context-awareness or context-aware computing as the use of context to provide task-relevant information and/or services to a user. Three important context-awareness behaviours are the presentation of information and services to a user, automatic execution of a service, and tagging of context to information for later retrieval''. \cite{abowd1999towards}. Context-awareness takes HCI to a whole different level. We are not thinking anymore of only sitting down in front of a computer and interacting with it using a few peripherals. Users and developers have a whole new spectrum they can explore, in dynamic and continuously evolving technological environment. Take for example a piece of software that gives information on historical monuments. If this software is running on a PC, the user would manually search for a specific monument to retrieve the information. The same software running on a mobile device with localization capabilities (i.e. GPS), could take away all the explicit interaction by determining the user's location and if this is in near proximity of a certain historical monument, the displaying the relevant information.\\

While designing mobile pervasive computing environments, software developers are bound to work with cutting edge hardware and software technologies and to adopt new communication models for HCI. Throughout the years, in ubicomp much of the effort has been devoted to address hardware and software challenges, but the area of designing systems in which device are distributed as such has been barely touched. Hence, with the explosion of devices in the form of mobile phones and tablets having a wide range of sensing capabilities, modeling of context-awarene software became \emph{device-centric}. This means that designers of mobile context-aware systems base their design mostly on device sensory data.\\

In our everyday lives we encounter and interact with a wider range of mobile device. But the spectrum of everyday, physical objects we interact a lot broader. As context modeling became device centric, physical objects have been greatly overlooked making it a challenge to work design for them in a pervasive system. To address the struggling on conceptually incorporating the real world into the system design, Pederson in \cite{pederson2010towards} introduced a \emph{body-centric} modeling framework that incorporates physical and virtual objects of interest on the basis of proximity and human perception, framed in the context of an emerging ''egocentric'' interaction paradigm. ''Egocentric'' signals that it is the human body and mind of a specific human individual that acts as center of reference to which all modeling is anchored in this interaction paradigm. Part of the egocentric paradigm is the Situative Space Model (SSM): an interaction model and a design tool which captures what a specific human agent can perceive and not perceive, reach and not reach, at any given moment in time.\\

Evaluating the SSM consisted in creating a real-life setup, with digitally enhanced physical objects (various sensors to track agent proximity) and using a wide range of technologies to track the agent's current situation (body position, orientation, visual spectrum etc.). This is a costly and time consuming process making further development and evaluation of the egocentric paradigm a challenge. As Pederson also stated in \cite{pederson2011situative}: ''accurate tracking of objects and mediators needed for real-time application of the SSM will probably remain a challenge for years to come''.\\

In this Master Thesis we aim at designing and developing a simulation environment for mobile context-aware system design, while modeling our framework to fit all SSM related concepts.\\

Finally, I want to emphasize on the need for this simulator, relating to the need for simulators in ubicomp as identified by Reynolds, Cahill and Senart in \cite{reynolds2006requirements}: ''The use of simulation technology in ubiquitous computing is of particular importance to developers and researchers alike. Many of the required hardware technologies such as cheap reliable sensors are only reaching maturity now, and many of the application scenarios are being designed with the future in mind and well in advance of the hardware actually being available. Furthermore, many of the target scenarios do not lend themselves to onsite testing, in particular, scenarios which require deployment of large numbers of nodes or devices. In addition, simulation enables researchers to evaluate scenarios, applications, protocols and so forth without the difficulties in dealing with hardware sensors and actuators, and also offers greater flexibility since it is easy to run a set of simulations with a range of parameters''.\\

\input{Chapters/Chapter01/ProblemStatement}

\input{Chapters/Chapter01/Goal}

\input{Chapters/Chapter01/Method}

\input{Chapters/Chapter01/ThesisOverview}

