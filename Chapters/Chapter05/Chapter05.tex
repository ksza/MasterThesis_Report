%************************************************
\chapter{Evaluation}\label{ch:evaluation}
%************************************************
Our objective with this project was to design and implement an open-source simulation framework that can help developers of mobile context-aware systems to explore design alternatives. The framework was to dynamically classify physical objects, virtual objects and mediators that are close to the human agent according to the situative space model, with the human agent represented as an avatar that can move around and perform basic interaction with objects in the simulated environment.\\

In Section \ref{subsec:user_roles} we have identified three User Roles for the EgoSim framework. To evaluate to what extent we have met the goals defined in Section \ref{sec:goal}, we conducted an evaluation in two parts. First we have evaluated a simulation created with the EgoSim framework from the simulation user's perspective. The users were able to explore a ready made simulation while observing contextual changes in the context client. Second, we have evaluated the EgoSim framework from the system designer's perspective. The users had to build a simulation using our framework.\\

% For a complete assessment of the framework, we should have covered the third role as well, evaluating the system from a third party system's point of view. Normally, we would have asked the participants to build a piece of software which connect to our API and implements some business login on top of the retrieved data. Instead, to reduce the evaluation time, in the second evaluation step we gathered feedback about the API from the participants point of view. Moreover, we provided a task the where the participants had to 
\input{Chapters/Chapter05/Participants}
\input{Chapters/Chapter05/Procedure}
\input{Chapters/Chapter05/Discussion}
\input{Chapters/Chapter05/FutureWork}